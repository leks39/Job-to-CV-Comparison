{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c95f056c-9f7b-4c6a-91ce-f7fbb397273b",
   "metadata": {},
   "source": [
    "## Resume to Job Description Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e7d724-5142-44f3-a06d-fb154a7e4e54",
   "metadata": {},
   "source": [
    "_Author: Olalekan Fagbuyi_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba41d57-f146-4c89-9358-a4445716d2e3",
   "metadata": {},
   "source": [
    "Ever seen an online job posting and wondered if you are a fit based on details on your CV(resume)? With text processing libraries such as docx2txt and sklearn library tools like; Count Vectorizer and Cosine Similarity allows candidates to compare similarities between their CVs and company's job posting. This skills could help optmize the job search process by allowing candidates focus on job postings that are the best fit for their current level of experience. \n",
    "\n",
    "It is also important to note that companies use software like Applicants Tracking System(ATS) built on similar techniques to search for qualified candidates from a large pool of applicants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a038df8-b4ba-4023-97ce-c47d18c9c9e8",
   "metadata": {},
   "source": [
    " ### Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deecad83-ef70-4c45-9743-25f05939c3bc",
   "metadata": {},
   "source": [
    "1. Importing Libraries\n",
    "2. Reading Documents (CV and Job Posting)\n",
    "3. Applying Count Vectorization and Calculating Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b706d5d9-4a28-4143-a3e7-b8b419f5d024",
   "metadata": {},
   "source": [
    "### 1. Import Libaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84152a5-f1b0-463a-addf-74201b7a3670",
   "metadata": {},
   "source": [
    "This project uses text processing library **docx2txt** for reading and processing text documents. Also, CountVectorizer and Cosine Similarity were imported from SciKit Learn to compare similaries between documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bd0ab6e-2665-4b80-83c1-bd6269c2d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import docx2txt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b223ae3-1780-49ec-bf65-87f9631ed043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ola_CV.docx\n",
      "Walmart_Job_Posting.docx\n"
     ]
    }
   ],
   "source": [
    "#upload data - 2 documents will be uploaded here. 1st is a resume and the 2nd a job posting\n",
    "#printing all sales file from directory\n",
    "path = \"C:\\\\Users\\\\ofagb\\\\Job to CV\"\n",
    "files = [file for file in os.listdir(path) if not file.startswith('.')]\n",
    "for file in files:\n",
    "    print (file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0d5965-1dc6-4b3e-a744-15931da98fc8",
   "metadata": {},
   "source": [
    "### 2. Reading CV and Job Posting Dcoument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ba14d2-1878-4ed7-a956-fe725cc80663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in CV file\n",
    "CV = docx2txt.process(\"C:\\\\Users\\\\ofagb\\\\Ola_CV.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8f1b27-afae-4ff9-b9bc-648e9f5412f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print CV content\n",
    "print(CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf567c8d-c0bf-4890-8102-5ddf71a2ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read job posting file\n",
    "Job_Posting = docx2txt.process(\"C:\\\\Users\\\\ofagb\\\\Walmart_Job_Posting.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50e30e42-ed9f-4799-9e4a-a614978bb8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Scientist\n",
      "\n",
      "SAVE\n",
      "\n",
      "\n",
      "\n",
      "Walmart\n",
      "\n",
      "Mississauga, ON, Canada\n",
      "\n",
      "\n",
      "\n",
      "Apply on TalentEgg\n",
      "\n",
      "\n",
      "\n",
      "Full–time\n",
      "\n",
      "Position Summary... \n",
      "\n",
      "The Data Scientist represents the foundation of a data driven culture that has made Wal-Mart a leader in the retail industry. Individual in this role will use a wealth of ecommerce, physical store and external data available to understand customer behaviour improve operational efficiencies and provide actionable insights to stakeholders so they can make smarter, data-driven decisions.\n",
      "\n",
      "The successful candidate will have an established background in solving complex problems, a strong technical ability, excellent project management skills, great communication skills, and the motivation to achieve results in a fast-paced environment. \n",
      "\n",
      "\n",
      "\n",
      "Our team is small, creative, diligent, highly entrepreneurial and business-focused. What you'll do... \n",
      "\n",
      "• Lead the data science development process with hands-on analysis and modeling, drawing from multiple of analytical methods to choose the right tool and right level of complexity appropriate for the business challenges. \n",
      "\n",
      "• Articulate business questions and use mathematical techniques to arrive at an answer using data; Translate analysis results into business recommendations.\n",
      "\n",
      " • Identify and communicate the challenges and opportunities that the data science team should be working on. \n",
      "\n",
      "• Help define the analytical direction and influence the direction of the associated engineering and infrastructure work; Perform ad-hoc analysis and present results concisely and persuasively to stakeholders. \n",
      "\n",
      "• Create production-ready code for deployment into clusters and/or other API’s; Determine the tracking necessary to enable our products and features by working closely with product, marketing, operations and engineering partners. \n",
      "\n",
      "• Engage broadly with the organization to identify, prioritize, frame, and structure complex and ambiguous challenges, where advanced analytics projects or tools can have the biggest impact. \n",
      "\n",
      "• Build metrics, reports and dashboards imbedded with data science algorithms using various visualization tools (e.g. Tableau, RShiny/flex, plotly/dash dashboards). \n",
      "\n",
      "• Enable others in the organization to utilize your work by sharing your work as well as act as an ambassador for Data Science within Walmart Canada. \n",
      "\n",
      "\n",
      "\n",
      "Qualifications: \n",
      "\n",
      "• Degree in a STEM discipline (applied mathematics, computer science, statistics, engineering, machine learning, econometrics etc.) with 3-5 years of commercial experience in a data science role solving high impact business problems. \n",
      "\n",
      "• Experience creating data product strategies, data products, iterating after launch, and optimizing by continuously improving the underlying algorithm/logic. \n",
      "\n",
      "• Experience understanding, applying and tuning AI algorithms (supervised and unsupervised learning).\n",
      "\n",
      " • Track record of diving into data to discover hidden patterns and conducting error/deviation analysis. \n",
      "\n",
      "• Ability to develop experimental and analytic plans for data modeling processes, and to accurately determine cause and effect relationships. • Proficient/experience in Python (or similar scripting language), SQL and big data tools such as Hive, Spark, etc. \n",
      "\n",
      "• Comfortable working in a cross-functional role, as well as seeing opportunity within ambiguity. • Curious, hunger for innovation and an appetite for learning. • Must be able to explain technical concepts and analyses implications (tell a data story) clearly to a wide business audience/possess excellent communication skills and be able to translate business objectives into actionable analyses. \n",
      "\n",
      "• Experience in e-commerce or a related field and GCP/Big Query/BQ ML would be considered as an asset. \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Minimum Qualifications... \n",
      "\n",
      "Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications. Age - 16 or older Preferred Qualifications... \n",
      "\n",
      "Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications. \n",
      "\n",
      "Walmart will accommodate the disability-related needs of applicants and associates as required by law. \n",
      "\n",
      "\n",
      "\n",
      "Primary Location… 1940 ARGENTIA RD, MISSISSAUGA, ON L5N 1P9, Canada\n"
     ]
    }
   ],
   "source": [
    "#print Job_Posting\n",
    "print(Job_Posting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5983a3f4-c38d-4469-bc5c-edf0b0a4ae92",
   "metadata": {},
   "source": [
    "### 3. Applying Count Vectorization and Calculating Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e9e7e17-bfa7-427a-a01a-39ba00d9c481",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list containing both CV and Job posting\n",
    "Job_CV = [CV, Job_Posting]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d374b6e7-7ac7-4b58-bc1a-26ab9166032e",
   "metadata": {},
   "source": [
    "### Count Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6973130-04fa-4646-9490-6a2d80df5683",
   "metadata": {},
   "source": [
    "CountVectorizer from the scikit-learn library is used to transform a given text into a vector on the basis of the frequency of each word that occurs in the entire text. This is helpful when there are multiple such texts, and each there is need to convert each word in each text into vectors to be used in further text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4dcf45b6-eebe-47f3-bcf6-124029562eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use count vectorizer to determine similarities between both documents\n",
    "Count_Vect = CountVectorizer()\n",
    "Count_Matrix = Count_Vect.fit_transform(Job_CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a3c321-52e6-4809-8f3b-341a3b880dbd",
   "metadata": {},
   "source": [
    "### Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f66c891-bb0c-4c49-afcd-9c0e1eb12bea",
   "metadata": {},
   "source": [
    "Cosine Similarity measures resemblance between 2 vectors. It measures the cosine of the ange between the 2 vectors and determines if they are pointing in the same direction. This technique is often used to measure document similarity in Text Analysis. A score of 0.5 is usually considered to signify a high similarity between documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3decf299-3e39-4940-b131-39cef4317bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity Scores:\n",
      "[[1.         0.64196146]\n",
      " [0.64196146 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Printing Cosine Similarity Scores\n",
    "print(\"\\nSimilarity Scores:\")\n",
    "print(cosine_similarity(Count_Matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09e13f18-8d46-4a96-9b70-a060e33dc407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your CV matches about 64.2% of the job posting.\n"
     ]
    }
   ],
   "source": [
    "#converting score to a percentage\n",
    "Similarity_Percent = cosine_similarity(Count_Matrix)[0][1] * 100\n",
    "Similarity_Percent = round(Similarity_Percent, 2) #rounding scores to 2 decimal place\n",
    "print(\"Your CV matches about \" + str(Similarity_Percent)+ \"% of the job posting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6a13b0-baaa-402d-89e5-7e3ec8264373",
   "metadata": {},
   "source": [
    "Conclusion: Guess I will be applying for this one :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a2db74-dead-4a7f-8b1a-75ef49e9386f",
   "metadata": {},
   "source": [
    "### 4. Keywords Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9581ad6-1867-4aab-9a4b-84ad06f03149",
   "metadata": {},
   "source": [
    "Checking if keywords from the job postings that could strengthen the match was missed in the CV. Spacy library will be used to carry this task out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b8d433c7-6f1c-4180-ad9d-e3650fd132ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "39d4e44e-fe10-45c6-bf59-819f623c5086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('to', 20), ('and', 19), ('of', 14), ('in', 10), ('the', 8), ('by', 8), ('on', 6), ('Lagos', 5), ('com', 5), ('Business', 5), ('2022', 5), ('Data', 5), ('with', 5), ('s', 5), ('Pizza', 5), ('Hut', 5), ('Nigeria', 4), ('Tableau', 4), ('R', 4), ('using', 4), ('sales', 4), ('1', 3), ('Science', 3), ('Analytics', 3), ('University', 3), ('Focus', 3), ('Supply', 3), ('Chain', 3), ('Cape', 3), ('Town', 3)]\n"
     ]
    }
   ],
   "source": [
    "CV = docx2txt.process(\"C:\\\\Users\\\\ofagb\\\\Ola_CV.docx\")\n",
    "counts =  Counter(re.findall('\\w+', CV)).most_common(30)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cbbaffdc-8bb2-4fad-b756-523a136e0772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('and', 32), ('the', 19), ('to', 15), ('data', 14), ('a', 11), ('in', 10), ('of', 8), ('for', 8), ('as', 8), ('business', 7), ('are', 6), ('an', 5), ('science', 5), ('with', 5), ('or', 5), ('analysis', 4), ('into', 4), ('be', 4), ('by', 4), ('qualifications', 4), ('Data', 3), ('Walmart', 3), ('Canada', 3), ('on', 3), ('this', 3), ('role', 3), ('will', 3), ('skills', 3), ('results', 3), ('challenges', 3)]\n"
     ]
    }
   ],
   "source": [
    "Job_Posting = docx2txt.process(\"C:\\\\Users\\\\ofagb\\\\Walmart_Job_Posting.docx\")\n",
    "counts2 =  Counter(re.findall('\\w+', Job_Posting)).most_common(30)\n",
    "print(counts2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
